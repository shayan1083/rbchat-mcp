from mcp.server.fastmcp import FastMCP
from settings import Settings
from user_repository import UserRepository
from llm_logger import LLMLogger
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from langchain_google_community import GoogleSearchAPIWrapper
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_tavily import TavilySearch
import base64
import csv
from datetime import datetime, date
import io
from openai import OpenAI
import time

client = OpenAI()

settings = Settings()
logger = LLMLogger()

mcp = FastMCP("RBChat")

def get_db_name() -> str:
    return mcp.get_context().request_context.request.headers.get("db_name", settings.DB_NAME)

@mcp.tool()
def allocate_top_selling_sku(units:int,transaction_date:date) -> str:
    """
    This tool is used to allocate top selling sku codes to stores
    
    Args:
    -  units : shipment quantity
    -  transaction_date : transaction date of sale

    Returns:
        A formatted string or JSON of the result rows.
    """
    query = f"""
    WITH filtered_data AS (
    SELECT skucode, store, SUM(quantity_sold) AS total_sold 
    FROM sales_for_sku
    WHERE skucode IN (
        SELECT skucode
        FROM sales_for_sku
        WHERE transaction_date = '{transaction_date}'
        GROUP BY skucode
        ORDER BY SUM(quantity_sold) DESC limit 10
            )  
            GROUP BY skucode, store
        ),
        sku_totals AS (
            SELECT skucode, SUM(total_sold) AS sku_total
            FROM filtered_data
            GROUP BY skucode
        ),
        allocations AS (
            SELECT 
                f.skucode,
                f.store,
                f.total_sold,
                s.sku_total,
                ROUND((f.total_sold::numeric / NULLIF(s.sku_total,0)) * {units}) AS allocated_units
            FROM filtered_data f
            INNER JOIN sku_totals s ON f.skucode = s.skucode
        )
        SELECT skucode, store, total_sold, sku_total, allocated_units
        FROM allocations
        ORDER BY skucode, allocated_units DESC, store
        LIMIT 10000
    """
    start_time = time.perf_counter() 
    

    try:
        return export_user_query_to_file(query)        
    except Exception as e:
        logger.error(f"(MCP) Error running SQL query: {e}")
        return f"Query failed: {e}"
    finally:
        elapsed_time = time.perf_counter() - start_time
        logger.log_sql_output(f"SQL Query Ran: {query}; Query Execution Time: {elapsed_time}")


@mcp.tool()
def run_sql_query(query: str) -> str:
    """
    Executes a safe, read-only database SELECT query and returns the results.

    Args:
        query: A database language SELECT query generated by the LLM, such as SQL

    Returns:
        A formatted string or JSON of the result rows.
    """
    start_time = time.perf_counter() 
    if not query.strip().lower().startswith("select"):
        return "Only SELECT queries are allowed."

    try:
        with UserRepository(get_db_name()) as user_repo:
            result = user_repo.run_sql_query(query)
        return str(result)
    except Exception as e:
        logger.error(f"(MCP) Error running SQL query: {e}")
        return f"Query failed: {e}"
    finally:
        elapsed_time = time.perf_counter() - start_time
        logger.log_sql_output(f"SQL Query Ran: {query}; Query Execution Time: {elapsed_time}")



@mcp.tool()
def search_internet(query: str) -> str:
    """
    Searches the internet using Tavily Search api and returns the results.

    Args: 
        query: The search query string to be executed. It should be exactly what the user asked.
    
    Returns:
        A string containing the search results.
    """
    start_time = time.perf_counter() 
    try:
        searchTool="OpenAI Api"
        if settings.OPENAI_API_KEY:
            response = client.responses.create(
                model="gpt-4.1",
                tools=[{"type": "web_search_preview"}],
                input=query,
            )
            res = response.output_text
        elif settings.TAVILY_API_KEY:
            searchTool="Tavily"
            search = TavilySearch(max_results=5, time_range='week')
            res = search.invoke(query)
        else:
            logger.error(f"(MCP) No internet search api key available")
            return "Error"
        return res
    except Exception as e:
        logger.error(f"(MCP) Error using internet_search: {e}")
    finally: 
        elapsed_time = time.perf_counter() - start_time
        logger.info(f"(MCP) {searchTool} searched {query}; Output: {res}; Execution Time: {elapsed_time}")

@mcp.tool()
def processed_file(file: dict) -> dict:
    """
    Save the processed file for the user into a database.

    Args:
        file: A dictionary with keys:
              - 'filename': name of the file (e.g. 'cleaned_data.csv')
              - 'content': either raw text or base64-encoded string
              - 'file_type': MIME type, e.g. 'text/csv'

    Returns:
        Dictionary with file info or error message.
    """

    try:
        content = file['content']
        file_type = file.get("file_type", "")

        if file_type.startswith("text/"):
            content_bytes = content.encode("utf-8")
        else:
            missing_padding = len(content) % 4
            if missing_padding:
                content += '=' * (4 - missing_padding)
            content_bytes = base64.b64decode(content)


        with UserRepository() as user_repo:
            result = user_repo.save_binary_file_from_mcp(
                filename=file["filename"],
                file_type=file["file_type"],
                content=content_bytes,
            )
        return result
    except Exception as e:
        logger.error(f"(MCP) Error saving file: {e}")
        return {"error": f"Save failed: {e}"}

@mcp.tool()
def export_user_query_to_file(query: str):
    """
        Export the database query results into a file

        Args:
            query: llm generated database query

        Returns:
            Dictionary with file info or error message.
    """
    logger.info(f"(MCP) Exporting query: {query}")
    with UserRepository(get_db_name()) as user_repo:
            result = user_repo.run_sql_query(query)

    if not result:
        return "No data found for given query"
    
    output = io.StringIO()
    writer = csv.DictWriter(output, fieldnames=result[0].keys())
    writer.writeheader()
    writer.writerows(result)

    csv_content = output.getvalue().encode("utf-8")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"query_result_{timestamp}.csv"
    with UserRepository() as user_repo:
            result = user_repo.save_binary_file_from_mcp(
                filename=filename,
                file_type='text/csv',
                content=csv_content,
            )
    logger.info(f'Export Result: {result}')
    return result

mcp_app = mcp.streamable_http_app()
app = FastAPI(lifespan=mcp_app.router.lifespan_context)


app.mount("/mcp-server", mcp_app, "mcp")

app.add_middleware(
    CORSMiddleware,
    allow_origins=[settings.ALLOWED_ORIGINS],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/api/healthcheck")
async def health_check():
    return {"status": 200, "message": "MCP server is running"}

# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run("tools:app", port=7999, reload=True)

# uvicorn tools:app --reload --port 7999
